cv_roc_auc,cv_accuracy,cv_precision,cv_recall,cv_f1,cv_score_mean,cv_score_std,test_roc_auc,test_accuracy,test_precision,test_recall,test_f1,overfitting_gap,accuracy_ci_lower,accuracy_ci_upper,precision_ci_lower,precision_ci_upper,recall_ci_lower,recall_ci_upper,f1_ci_lower,f1_ci_upper,roc_auc_ci_lower,roc_auc_ci_upper,final_features,model_path,model_checksum,scaler_path,scaler_checksum,metadata_path,metadata_checksum,timestamp,package_versions
0.9070247933884298,0.8409090909090909,0.8,0.9090909090909091,0.851063829787234,0.9099999999999999,0.11135528725660043,0.7333333333333333,0.75,0.6,1.0,0.75,0.09090909090909094,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,"[{""feature"": ""worship_to_vigilance_ratio"", ""importance"": 0.4188665816033103}, {""feature"": ""loan_to_saving_ratio"", ""importance"": 0.234726801455713}, {""feature"": ""kmsi8"", ""importance"": 0.18304058638965404}, {""feature"": ""kmsi6"", ""importance"": 0.16336603055132273}]",save_models/custom_model_20250629_181253.pkl,653d601ef5ea195a80f4711ae919eab51a4abe2cd49b2c50cd38ab29f1e71161,save_scalers/custom_scaler_20250629_181253.pkl,d7e75686df979ea262ce4ccb36c2ace98fc2fc5d9cb1678c8ffa132d77789da4,,,20250629_181253,"{""sklearn"": ""1.6.1"", ""joblib"": ""1.3.2"", ""pandas"": ""1.5.3"", ""numpy"": ""1.26.4""}"
