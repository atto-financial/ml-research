cv_roc_auc,cv_accuracy,cv_precision,cv_recall,cv_f1,cv_score_mean,cv_score_std,test_roc_auc,test_accuracy,test_precision,test_recall,test_f1,accuracy_ci_lower,accuracy_ci_upper,precision_ci_lower,precision_ci_upper,recall_ci_lower,recall_ci_upper,f1_ci_lower,f1_ci_upper,roc_auc_ci_lower,roc_auc_ci_upper,overfitting_gap,cost_loss,final_features,model_path,model_checksum,scaler_path,scaler_checksum,metadata_path,metadata_checksum,timestamp,decision_threshold,scoring,n_estimators,max_depth,min_samples_split,n_features_to_select,n_folds,random_state,oversampling_method,categorical_features,use_undersampling,max_vif,n_bootstraps,alpha,test_size,memory_threshold,cost_weight,package_versions
0.9851279000594884,0.926829268292683,0.926829268292683,0.926829268292683,0.926829268292683,0.925,0.06123724356957946,0.43181818181818177,0.8461538461538461,1.0,0.0,0.0,0.6500236769652681,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.08333333333333337,0.8636363636363636,0.08067542213883683,0.0,"[{""feature"": ""loan_extravagance_interaction"", ""importance"": 0.3635537842235904}, {""feature"": ""extravagance_to_spending_ratio"", ""importance"": 0.21946322228342588}, {""feature"": ""kmsi3"", ""importance"": 0.18739783370897098}, {""feature"": ""kmsi8"", ""importance"": 0.1438771991675429}, {""feature"": ""kmsi7"", ""importance"": 0.08570796061646994}]",save_models/custom_model_20250802_151453.pkl,9ffc5cc92bc1b8c89dd8c13ce731052562f6fc80c60780aeb5ed74a1d775d16e,save_scalers/custom_scaler_20250802_151453.pkl,42ff3d1151bd977dab2aa6111cf55546821eec4602b52fa3cda287922272a2b9,,,20250802_151453,0.5,f1,"[50, 100, 200]","[3, 5, 10, null]","[2, 5, 10]",10,5,42,borderline,[],False,1.5,500,0.05,0.2,1000000000,"{""0"": 1, ""1"": 1}","{""sklearn"": ""1.6.1"", ""joblib"": ""1.3.2"", ""pandas"": ""1.5.3"", ""numpy"": ""1.26.4""}"
